{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivakrishnaah/advanced_deep_learning/blob/main/PixelCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-AMvIot47Ph"
      },
      "source": [
        "Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6RnL0IwX306K"
      },
      "outputs": [],
      "source": [
        "#! /usr/bin/env python\n",
        "\n",
        "import os\n",
        "import time\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn, optim, cuda, backends\n",
        "from torch.autograd import Variable\n",
        "from torch.utils import data\n",
        "from torchvision import datasets, transforms, utils\n",
        "backends.cudnn.benchmark = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jmqu52uS5xTu"
      },
      "source": [
        "## [Pixel CNN paper ](https://arxiv.org/abs/1606.05328)\n",
        "### Mask Type A\n",
        "\t- Used in the first convolutional layer.\n",
        "\t- Ensures that the current pixel cannot see itself during prediction.\n",
        "\t- The mask removes the center pixel and all future pixels in both row and column directions.\n",
        "\n",
        "### Mask Type B\n",
        "\t- Used in subsequent convolutional layers.\n",
        "\t- Allows the network to see the current pixel but not future pixels.\n",
        "\t- The mask removes only future pixels, while the current pixel remains accessible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KLn9GYZ5AoH"
      },
      "outputs": [],
      "source": [
        "class MaskedConv2d(nn.Conv2d):\n",
        "    def __init__(self, mask_type, in_channels, out_channels, kernel_size, stride, padding, bias=True):\n",
        "        super(MaskedConv2d, self).__init__(in_channels, out_channels, kernel_size, stride, padding, bias=bias)\n",
        "        assert mask_type in {'A', 'B'}\n",
        "        self.register_buffer('mask', self.weight.data.clone())\n",
        "        _, _, height, width = self.weight.size()\n",
        "        self.mask.fill_(1)\n",
        "        yc, xc = height // 2, width // 2\n",
        "        self.mask[:, :, yc, xc+ (mask_type == 'B'):] = 0\n",
        "        self.mask[:, :, yc + 1:] = 0\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.weight.data *= self.mask\n",
        "        return super(MaskedConv2d, self).forward(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1RpEgm575Fvl"
      },
      "outputs": [],
      "source": [
        "class PixelCNN(nn.Module):\n",
        "  def __init__(self, input_channels=3, n_filters=64, kernel_size=7, n_layers=8) -> None:\n",
        "      super(PixelCNN, self).__init__()\n",
        "      layers = []\n",
        "      layers.append(MaskedConv2d('A', input_channels, n_filters, kernel_size, 1, padding=kernel_size//2, bias=False))\n",
        "      layers.append(nn.BatchNorm2d(n_filters))\n",
        "      layers.append(nn.ReLU(True))\n",
        "\n",
        "      for i in range(n_layers -1):\n",
        "          layers.append(MaskedConv2d('B', n_filters, n_filters, kernel_size, 1, padding=kernel_size//2, bias=False))\n",
        "          layers.append(nn.BatchNorm2d(n_filters))\n",
        "          layers.append(nn.ReLU(True))\n",
        "          # nn.Conv2d(in_channels=input_channels,  out_channels=input_channels*256, kernel_size=7, padding=3)\n",
        "      layers.append(nn.Conv2d(in_channels=n_filters, out_channels=input_channels * 256, kernel_size=1))\n",
        "      self.net = nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "      return self.net(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "mxJHM9OO5J9D"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def training_model(model, train_loader, optimizer, device, epochs=10, loss_function=F.cross_entropy):\n",
        "    # Detect the channels from the input\n",
        "    input_channels = next(iter(train_loader))[0].shape[1]\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for x, _ in train_loader:\n",
        "            x_input = x.to(device).float()\n",
        "            logits = model(x_input)\n",
        "            if loss_function.__name__ == \"discretized_logistic_loss\":\n",
        "                # ✅ PixelCNN++ path: do NOT reshape logits\n",
        "                loss = loss_function(x_input, logits)\n",
        "\n",
        "            else:\n",
        "                # ✅ PixelCNN path: standard cross entropy loss\n",
        "                x_int = (x * 255).long()\n",
        "                batch_size, _, height, width = logits.shape\n",
        "                logits = logits.view(batch_size, x.shape[1], 256, height, width)\n",
        "                logits = logits.permute(0, 3, 4, 1, 2).contiguous()\n",
        "                logits = logits.view(-1, 256)\n",
        "                targets = x_int.view(-1)\n",
        "                loss = loss_function(logits, targets)\n",
        "\n",
        "            # Backpropagation\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch+1}: Loss = {avg_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGmO0ewe5MsK",
        "outputId": "e3b5d5a2-5410-4ab5-bc04-1c9907f15d45"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:01<00:00, 5.11MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 134kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.27MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 9.47MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: Loss = 1.3173\n",
            "Epoch 2: Loss = 0.7900\n",
            "Epoch 3: Loss = 0.7625\n",
            "Epoch 4: Loss = 0.7494\n",
            "Epoch 5: Loss = 0.7405\n",
            "Epoch 6: Loss = 0.7334\n",
            "Epoch 7: Loss = 0.7272\n",
            "Epoch 8: Loss = 0.7213\n",
            "Epoch 9: Loss = 0.7147\n",
            "Epoch 10: Loss = 0.7073\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "train_loader = data.DataLoader(\n",
        "    datasets.MNIST('data', train=True, download=True, transform=transform),\n",
        "    batch_size=128, shuffle=True\n",
        ")\n",
        "sample_batch, _ = next(iter(train_loader))\n",
        "input_channels = sample_batch.shape[1]\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "minst_model = PixelCNN(input_channels=input_channels, n_filters=64).to(device)\n",
        "optimizer = torch.optim.Adam(minst_model.parameters(), lr=1e-3)\n",
        "training_model(minst_model, train_loader, optimizer, device, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cuMBtwwf5Pw2"
      },
      "outputs": [],
      "source": [
        "import torchvision.utils as vutils\n",
        "\n",
        "def sample(model, img_size=(28, 28), n_channels=1, n_samples=64):\n",
        "    model.eval()\n",
        "    samples = torch.zeros(n_samples, n_channels, *img_size).to(device)\n",
        "    with torch.no_grad():\n",
        "        for i in range(img_size[0]):\n",
        "            for j in range(img_size[1]):\n",
        "              for c in range(n_channels):\n",
        "                logits = model(samples)\n",
        "                logits = logits.view(n_samples, n_channels, 256, img_size[0], img_size[1])\n",
        "                probs = F.softmax(logits[:, c, :, i, j], dim=1)  # [n_samples, 256]\n",
        "                pixel_values = torch.multinomial(probs, num_samples=1).squeeze(-1)  # Sample pixel\n",
        "                samples[:, c, i, j] = pixel_values.float() / 255.0\n",
        "    return samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0V_8LLT5R3w"
      },
      "outputs": [],
      "source": [
        "samples = sample(minst_model, img_size=(28, 28), n_channels=1, n_samples=64)\n",
        "vutils.save_image(samples, \"pixelcnn_mnist_samples1.png\", nrow=8, padding=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKnoUMBN5Utk",
        "outputId": "e92b56fa-32bf-4631-a00f-15c7eb7208af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss = 5.2068\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "train_loader = data.DataLoader(\n",
        "    datasets.CIFAR10('data', train=True, download=True, transform=transform),\n",
        "    batch_size=128, shuffle=True\n",
        ")\n",
        "sample_batch, _ = next(iter(train_loader))\n",
        "input_channels = sample_batch.shape[1]\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "cifar_model = PixelCNN(input_channels=input_channels, n_filters=192, n_layers=15).to(device)\n",
        "optimizer = torch.optim.Adam(cifar_model.parameters(), lr=1e-3)\n",
        "training_model(cifar_model, train_loader, optimizer, device, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "SJ_KSjXt5XQr"
      },
      "outputs": [],
      "source": [
        "samples = sample(cifar_model, img_size=(32, 32), n_channels=3, n_samples=64)\n",
        "vutils.save_image(samples, \"pixelcnn_cifar10_samples.png\", nrow=8, padding=2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GatedMaskedConv2d(MaskedConv2d):\n",
        "    def __init__(self, mask_type, in_channels, out_channels, kernel_size, stride=1, padding=0, bias=True):\n",
        "        super(GatedMaskedConv2d, self).__init__(mask_type, in_channels, out_channels * 2, kernel_size, stride, padding, bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = super(GatedMaskedConv2d, self).forward(x)\n",
        "        out_filter, out_gate = out.chunk(2, dim=1)\n",
        "        return torch.tanh(out_filter) * torch.sigmoid(out_gate)"
      ],
      "metadata": {
        "id": "pkAtyHiMGHvr"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "1yllQfU19Qbq"
      },
      "outputs": [],
      "source": [
        "class PixelCNNpp(PixelCNN):\n",
        "    def __init__(self, input_channels=3, n_filters=64, kernel_size=7, n_layers=8, nr_mix=5):\n",
        "        super(PixelCNNpp, self).__init__(input_channels, n_filters, kernel_size, n_layers)\n",
        "        self.nr_mix = nr_mix\n",
        "        num_params = nr_mix * (3 * input_channels + (input_channels > 1) * 3)\n",
        "        self.net[-1] = nn.Conv2d(n_filters, num_params, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def discretized_logistic_loss(x, l):\n",
        "    \"\"\"\n",
        "    Simplified PixelCNN++ loss with a single logistic component.\n",
        "    x: [B,C,H,W] in [-1,1]\n",
        "    l: logits [B,C*3,H,W] -> mean, log_scale, logit_prob (no mixture)\n",
        "    \"\"\"\n",
        "    B, C, H, W = x.size()\n",
        "    l = l.permute(0, 2, 3, 1)  # [B,H,W,C*3]\n",
        "\n",
        "    means = l[..., :C]\n",
        "    log_scales = torch.clamp(l[..., C:2*C], min=-7.)\n",
        "\n",
        "    x = x.permute(0, 2, 3, 1)\n",
        "    centered_x = x - means\n",
        "    inv_stdv = torch.exp(-log_scales)\n",
        "\n",
        "    plus_in = inv_stdv * (centered_x + 1./255.)\n",
        "    cdf_plus = torch.sigmoid(plus_in)\n",
        "    min_in = inv_stdv * (centered_x - 1./255.)\n",
        "    cdf_min = torch.sigmoid(min_in)\n",
        "\n",
        "    log_cdf_plus = torch.log(cdf_plus.clamp(min=1e-12))\n",
        "    log_one_minus_cdf_min = torch.log((1. - cdf_min).clamp(min=1e-12))\n",
        "    cdf_delta = cdf_plus - cdf_min\n",
        "\n",
        "    log_probs = torch.where(x < -0.999, log_cdf_plus,\n",
        "                            torch.where(x > 0.999, log_one_minus_cdf_min,\n",
        "                                        torch.log(cdf_delta.clamp(min=1e-12))))\n",
        "\n",
        "    return -log_probs.mean()"
      ],
      "metadata": {
        "id": "7nINlBmQGSUB"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transform = transforms.Compose([\n",
        "#     transforms.ToTensor()\n",
        "# ])\n",
        "# train_loader = data.DataLoader(\n",
        "#     datasets.CIFAR10('data', train=True, download=True, transform=transform),\n",
        "#     batch_size=128, shuffle=True\n",
        "# )\n",
        "# sample_batch, _ = next(iter(train_loader))\n",
        "# input_channels = sample_batch.shape[1]\n",
        "\n",
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "FlSW5SBNM0nJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zG4chDs39ZsE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db24eb57-2e02-45f6-bcbd-63fe5ba59a45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss = 4.9278\n",
            "Epoch 2: Loss = 4.6382\n",
            "Epoch 3: Loss = 3.8745\n",
            "Epoch 4: Loss = 3.6185\n"
          ]
        }
      ],
      "source": [
        "cifar_model_pp = PixelCNNpp(input_channels=input_channels, n_filters=192, n_layers=15, nr_mix=10).to(device)\n",
        "optimizer = torch.optim.Adam(cifar_model_pp.parameters(), lr=1e-3)\n",
        "training_model(cifar_model_pp, train_loader, optimizer, device, epochs=10, loss_function=discretized_logistic_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0i5wFn89oHT"
      },
      "outputs": [],
      "source": [
        "samples = sample(cifar_model_pp, img_size=(32, 32), n_channels=3, n_samples=64)\n",
        "vutils.save_image(samples, \"pixelcnn_cifar10pp_samples1.png\", nrow=8, padding=2)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "authorship_tag": "ABX9TyMBzR6zq1aIsGLbnlDhH7C4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}